---
layout: post
title:  "Using APIs: Access NASA data (IN PROGRESS)"
date:   2022-10-16
author: Katelyn Nelson
description: Learn how to use an API in Python to access NASA's global landslide data
image: /assets/images/A325630C-D68B-42C9-8EB8-FBB0C428BEC2.JPEG
---

Every data analysis begins with 'data' (see what I did there? ðŸ˜‰). So where can you get data without putting the effort into collecting your own? An API (application programming interface) is a powerful tool that acts as a bridge between your device and a database so that you can access existing data. To use an API you need a unique 'key' that acts as a personal password to authenticate your access to the data. There are a lot of free APIs online that you can request keys for, but sometimes they require a paid subscription.

Even though the you can access data, make sure that you are using according to the source's conditions. I will be using NASA's Open Data Portal because has a ton of pictures, data, and other resources that are available for free as long as you agree to their Terms and Conditions and cite the data.

**Note:** I will not include all of my code in this post, but if you have difficulty following alon,, the Jupyter Notebook file that I used to complete the steps below can be found in my github repository [nasa_api](https://github.com/katelynnelson38/nasa_api).

# Set up

Before we can start, you will need to [create an account](https://data.nasa.gov/login) to NASA's Open Data Portal and [request an API key](https://api.nasa.gov/index.html#signUp). I recommend copying your API key and pasting it into text file to use for later use. In this post I will be using NASA's [Global Landslide Catalog Export](https://data.nasa.gov/Earth-Science/Global-Landslide-Catalog-Export/dd9e-wu2v) data.

I used the beautiful soup and requests packages in Python to use the NASA API, so make sure to import those. You'll need additional packages for the data cleaning, but I will not talk about those in depth.

```
from bs4 import BeautifulSoup
import requests
```

# Get the data

For privacy and legal purposes, I will not share my API key, but if you requested one it should work the same. I pasted mine into a file named `nasa_apikey.txt`. Substitute the name of your file, or the API key.

```
with open('nasa_apikey.txt', 'r') as file:
    nasa_key = file.read()

payload = {}

headers= {
  "apikey": nasa_key
}
```

Now you can use your key (stored as a header) to request data from the NASA database. Most often you specify which data you want by the url you use, which can usually be found in the online API documentation.

```
nasa_url = 'https://data.nasa.gov/resource/dd9e-wu2v.json'
r = requests.get(nasa_url, headers=headers, data = payload)
```

Use `.json()` to read the data and create a pandas dataframe.

```
landslide = r.json()
landslide_df = pd.DataFrame(landslide)
```

# Clean the data

Now that we have the data, we can use the `shape` attribute to see that it includes 1000 observations with 30 variables. Let's narrow it down to 9 variables that we might want to use for an analysis.

```
landslide_df = landslide_df[['event_date', 'landslide_category', 'landslide_trigger', 'landslide_size', 'fatality_count', 'injury_count', 'country_name', 'longitude', 'latitude']]
```

Use the `info()` function to understand the data better.
One powerful tool in exploring new data is the `info()` function. When you use the function on a dataframe (`df.info()`) it will return how many columns the dataframe has, how many non-null values each column has, and the variable type for each.

```
landslide_df.info()
```

![first info](https://raw.githubusercontent.com/katelynnelson38/stat386-projects/main/assets/images/apipost/first.info.PNG)

This data is has quite a few null values and all the variables are type object. We will have to fix this before the data is ready for an analysis. Let's start by filling in the null values.

The null values in `fatality_count` and `injury count` correspond with no fatalities or injuries
When landslide_size, landslide_trigger, and country_name are null, we will fill it with `unknown`


![second info](https://raw.githubusercontent.com/katelynnelson38/stat386-projects/main/assets/images/apipost/second.info.PNG)

![landslide df](https://raw.githubusercontent.com/katelynnelson38/stat386-projects/main/assets/images/apipost/cleaned_df.PNG)

# Save/Output the data

# Conclusion

Now you 

If you want to learn more about using APIs in Python, I recommend starting [here](https://wesmckinney.com/book/accessing-data.html#io_web_apis). 

Stay tuned ðŸ‘€ for my next post where I will do an EDA (exploratory data analysis) with the landslide dataframe we just created!

#### Sources

Kirschbaum, D. B., Adler, R., Hong, Y., Hill, S., & Lerner-Lam, A. (2010). A global landslide catalog for hazard applications: method, results, and limitations. Natural Hazards, 52(3), 561â€“575. doi:10.1007/s11069-009-9401-4.

Kirschbaum, D.B., T. Stanley, Y. Zhou (In press, 2015). Spatial and Temporal Analysis of a Global Landslide Catalog. Geomorphology. doi:10.1016/j.geomorph.2015.03.016.

(These are the citations I mentioned in the beginning ðŸ˜Š)
