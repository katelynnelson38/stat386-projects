---
layout: post
title:  "Beginner's Guide to Creating a Random Forest"
date:   2022-09-26
author: Katelyn Nelson
description: Use the iris dataset to train a random forest with tidymodels in R
image: /assets/images/olena-sergienko-3BlVILvh9hM-unsplash.jpg
---

Let me just start with a big disclaimer: I am not an expert on machine learning. I am just here to share what I know and maybe it will help someone else. Having said that, I LOVE the tidymodels packages in R. There can be a lot of different pieces, but I think they come together beautifully and I hope this example shows you why.

# Let's Begin!

Don't forget to load the tidyverse and tidymodels libraries before you begin.
For the sake of simplicity, we will be using the 'iris' dataset that is already built into R. I like to use the function `glimpse()` to take a peek at my data.
```
glimpse(iris)
```
We can see that this a fairly simple dataset that contains four explanatory variables that we will to train a model that predicts one of three iris species.

# Prepping the data

Because the data is pretty small (150 rows), we will use bootstrapping to simulate samples that will be used in training the random forest.
```
iris_boot <- bootstraps(iris)
```
One of my favorite parts of using tidymodels is the recipe feature. Recipes allow for quick and easy cleaning of your data before you use it to create a model. In this case the iris data is already very clean, but if the dataset was messy, you can include step functions in the recipe below. The `prep()` function applies the recipe to the data and the `juice` function will output the prepped data so you can take a look at what your recipe did.

```
iris_rec <- recipe(Species ~ ., data = iris) %>%
  step_center() %>%
  step_scale()

iris_prep <- prep(iris_rec)
juice(iris_prep)
```

# Creating a random forest model

The best thing to do when creating a random forest model is to give it a lot of trees. Here we will give it 1,000 trees and set the mode to classification because we are predicting a categorical response. You can also use the "randomForest" engine, but here we use "ranger". 
(You can put everything in the `rand_forest` function, but I like to use piping for clarity)
```
rf_model <- rand_forest(trees = 1000) %>%
  set_mode("classification") %>%
  set_engine("ranger")
```
Once we have prepped our recipe and created a model outline, we can add both to a workflow. Workflows are not crucial to creating a model, but they help organize the process into a clean format that comes in handy when we work with more complicated models.
```
iris_wf <- workflow() %>%
  add_recipe(iris_rec) %>%
  add_model(rf_model)
```
Output your workflow and see what you have so far!
```
iris_wf
```

# Evaluate the model

Now that we've created a random forest model (great job by the way) we want to see how well it performs. `fit_resamples()` will use the workflow and our bootstrapping samples to see how accurate the predictions are compared to the actual iris species.
(This may take a few minutes to run)
```
iris_resamples <- fit_resamples(
  iris_wf,
  resamples = iris_boot,
  control = control_resamples(save_pred = TRUE)
)
```
Once we've run the code above, we can extract the performance metrics with `collect_metrics()`. A great way to visualize the results of a classification model is a confusion matrix, so we will make one of those, too.
```
iris_resamples %>%
  collect_metrics()

iris_resamples %>%
  collect_predictions() %>%
  conf_mat(Species, .pred_class)
```

## Variable Importance

Just for fun, I'm also going to add code below that will tell you how important each variable is in predicting the iris species.

```
library(vip)

rf_model %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(Species ~ ., data = juice(iris_prep)) %>%
  vip()
```
